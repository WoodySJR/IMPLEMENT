# =============================================================================
# IMPLEMENT: World Model Training Configuration
# =============================================================================
# Based on Appendix Table 2 in the paper

# Model settings
model:
  base_model: "Qwen/Qwen2.5-VL-7B-Instruct"  # Base VLM for world model
  cache_dir: null  # Set to your HuggingFace cache directory

# Training hyperparameters (Table 2 in paper)
training:
  epochs: 3
  learning_rate: 2.0e-5
  per_device_train_batch_size: 4
  gradient_accumulation_steps: 4
  max_grad_norm: 0.2
  weight_decay: 0.01
  warmup_ratio: 0.03
  
  # Optimizer settings
  optimizer: "adamw_torch_fused"
  adam_beta1: 0.9
  adam_beta2: 0.999
  
  # Mixed precision
  bf16: true
  fp16: false

# LoRA configuration
lora:
  r: 16
  alpha: 16
  dropout: 0.05
  target_modules: "all-linear"
  bias: "none"
  task_type: "CAUSAL_LM"

# Data settings
data:
  num_samples: 35000  # Approximately 35K environment transitions
  train_split: 0.99
  val_split: 0.01
  
  # Data collection policy mixture (Section 3.2.2)
  collection_policy:
    admissible_prob: 0.4   # Random admissible actions
    inadmissible_prob: 0.4  # Random inadmissible actions
    expert_prob: 0.2        # Expert actions

# Loss weights
loss:
  perception_weight: 1.0
  prediction_weight: 1.0

